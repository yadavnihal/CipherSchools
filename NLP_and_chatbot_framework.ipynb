{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to NLP and chatbot frameworks\n",
        "\n",
        "Natural language processing is a field of artificial intelligence that focused on the interaction between computer and humans through natural language\n",
        "the ultimate goal of nlp is to enable computers to understand,interpret,and generate human languages in a way that is both meaningful and useful.\n",
        "\n",
        "Application of NLP:-\n",
        "\n",
        "\n",
        "*   Sentiment Analysis\n",
        "*   Language Translation\n",
        "*   Chatbots and Virtual assistants\n",
        "*   Text summurization\n",
        "*   Speech recognition\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ush05dBADimr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common NLP tasks\n",
        "\n",
        "**Tokenization**\n",
        "\n",
        "it is the process of breaking text into individual words or tokens\n",
        "\n",
        "**Stemming and Lemmatization**\n",
        "\n",
        "they are processes of reducing words to their root form or base form.\n",
        "\n",
        "**Stopwords removal**\n",
        "\n",
        "they are common words thaat add little meaning to text and are often removed in preprocessing"
      ],
      "metadata": {
        "id": "lIIEF4UOF9rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "text=\"My name is Nihal Yadav.\"\n",
        "words=word_tokenize(text)\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIdtXKKBHu_y",
        "outputId": "91fe3fff-6752-4fe5-b691-99e1ba89df92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'name', 'is', 'Nihal', 'Yadav', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "words=[\"running\",\"ran\",\"runs\"]\n",
        "stems=[stemmer.stem(word) for word in words]\n",
        "print(stems)\n",
        "#stemmer removes the suffix and make a word. it can be convert into non meaningful word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMUCKIxgLCC5",
        "outputId": "1182452f-7a85-427d-c1c0-8902f4db946d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'ran', 'run']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"ran\", \"runs\"]\n",
        "lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words] # pos reffers to part of speech and v means verb\n",
        "print(lemmas)\n",
        "# lemmatizer converts the word into base form on the basis of dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "961dGpBQMUT4",
        "outputId": "8d08a5e7-b179-4a29-c439-50b8f71b9c82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'run', 'run']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens=\"My name is Nihal Yadav\"\n",
        "tokens=word_tokenize(tokens)\n",
        "filtered_text=[word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSsw7DlhNyYt",
        "outputId": "6f81ecb9-1e43-4350-c41e-4ca2cf515a4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['name', 'Nihal', 'Yadav']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Chatbot Frame works\n",
        "\n",
        "**Chatterbot**\n",
        "\n",
        "it is a python library which is used to automated response to the user input\n",
        "\n",
        "**Ressa**\n",
        "\n",
        "it is an open source framework which is used to conversational AI,including chatbots and Voice assistants.\n",
        "\n"
      ],
      "metadata": {
        "id": "T5SAx3LsQp1S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WpcRth0iRbhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}